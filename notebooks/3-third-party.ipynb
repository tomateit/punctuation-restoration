{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75cf2774",
   "metadata": {},
   "source": [
    "### Exploring third-party solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d2e0b",
   "metadata": {},
   "source": [
    "https://github.com/vlomme/Bert-Russian-punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a5c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d142834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch_pretrained_bert.tokenization.BertTokenizer at 0x7f811acb4d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertTokenizer.from_pretrained(\"./vocab.txt\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b46dd1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert_punctuation(object):\n",
    "    def __init__(self):\n",
    "        self.model_file = \"bert_punctuation.tar.gz\"\n",
    "        self.vocab_file = \"vocab.txt\"\n",
    "        self.model = self.bert_model()\n",
    "        self.tokenizer = self.bert_tokenizer()\n",
    "\n",
    "    def bert_model(self):\n",
    "        model = BertForMaskedLM.from_pretrained(self.model_file).eval()\n",
    "        return model\n",
    "\n",
    "    def bert_tokenizer(self):\n",
    "        tokenizer = BertTokenizer.from_pretrained(self.vocab_file, do_lower_case=True)\n",
    "        return tokenizer\n",
    "    \n",
    "    def what_mask(self, text):\n",
    "        # Смотрим стоит запятая, или нет\n",
    "        w = self.tokenizer.tokenize(',')\n",
    "        w_i = self.tokenizer.convert_tokens_to_ids(w)\n",
    "        w = self.tokenizer.tokenize('^')\n",
    "        w_j = self.tokenizer.convert_tokens_to_ids(w)        \n",
    "        text = '[CLS] ' + text + ' [SEP]'\n",
    "        tokenized_text = self.tokenizer.tokenize(text)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        indexed_tokens = indexed_tokens[:500]\n",
    "        \n",
    "        mask_input = []\n",
    "        for i in range(len(indexed_tokens)):\n",
    "            if indexed_tokens[i] == 103:\n",
    "                mask_input.append(i)\n",
    "        segments_ids = [0] * len(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        masked_index = mask_input\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(tokens_tensor, segments_tensors)\n",
    "        predictsx1 = []\n",
    "        for i in range(len(mask_input)):\n",
    "            predictsx1.append(predictions[0,mask_input[i],:])\n",
    "            predicts1 = predictsx1[i].argsort()[-8:].numpy()\n",
    "            out1 = self.tokenizer.convert_ids_to_tokens(predicts1)\n",
    "        output = []\n",
    "        a = len(mask_input)\n",
    "        for i in range(a):\n",
    "            if predictsx1[i][w_i] > predictsx1[i][w_j]:\n",
    "                output.append(i+1)\n",
    "\n",
    "        return output\n",
    "      \n",
    "    def predict(self, texts):\n",
    "        words_all = texts\n",
    "        par_b = [['стар','млад'],  ['жив','мертв'],  ['день','ночь']]\n",
    "        sens = []\n",
    "        morph = pymorphy2.MorphAnalyzer()\n",
    "        for i,words in enumerate(words_all):\n",
    "            words = words.strip().lower()\n",
    "            choice_list = words.replace('–','-').replace('—','-').replace(',',' ,').replace('.',' .').replace('!',' !').replace('?',' ?').replace(':',' :').replace(';',' ;').replace('»',' »').replace('«','« ').split()\n",
    "            pos = ([str(morph.parse(ok)[0].tag.POS) for ok in choice_list])\n",
    "            case = ([str(morph.parse(ok)[0].tag.case) for ok in choice_list])\n",
    "            all_cases = ([morph.parse(ok) for ok in choice_list])\n",
    "            for j, p in enumerate(pos):            \n",
    "                eto_NOUN = False\n",
    "                bad_par = False\n",
    "                if p == 'PRTF' and (j==0 or pos[j-1] !='CONJ'):\n",
    "                    choice_list[j] = '[MASK] '+choice_list[j] \n",
    "                if p == 'VERB':\n",
    "                    for iii in range(j+1,min(len(pos),j+12)):\n",
    "                        if pos[iii] == 'NOUN':\n",
    "                            for all_cases_z in all_cases[iii]:\n",
    "                                if  all_cases_z.tag.case =='nomn':\n",
    "                                    #eto_NOUN = True\n",
    "                                    eto_NOUN = False\n",
    "                                    break\n",
    "                            if eto_NOUN:\n",
    "                                break\n",
    "                        if pos[iii] =='VERB' and pos[iii-1] !='CONJ':\n",
    "                            #print('Глагол',choice_list[j],choice_list[iii])\n",
    "                            choice_list[iii] = '[MASK] '+choice_list[iii]  \n",
    "                if p == 'INFN':\n",
    "                    for iii in range(j+1,min(len(pos),j+5)):\n",
    "                        if pos[iii] =='INFN' and pos[iii-1] !='CONJ':\n",
    "                            #print('Инфинитив',choice_list[j],choice_list[iii])\n",
    "                            choice_list[j] = choice_list[j]+ ' [MASK]'                \n",
    "                if p == 'ADVB':\n",
    "                    for iii in range(j+1,min(len(pos),j+3)):\n",
    "                        if pos[iii] =='ADVB' and pos[iii-1] !='CONJ':\n",
    "                            #print('Наречие',choice_list[j],choice_list[iii])\n",
    "                            choice_list[j] = choice_list[j]+ ' [MASK]'\n",
    "                if p == 'ADJF':\n",
    "                    for iii in range(j+1,min(len(pos),j+4)):\n",
    "                        if pos[iii] =='ADJF' and pos[iii-1] !='CONJ':\n",
    "                            if case[j] ==  case[iii]:\n",
    "                                #print('Прилогательное',choice_list[j],choice_list[iii])\n",
    "                                choice_list[j] = choice_list[j]+ ' [MASK]'\n",
    "                                break\n",
    "                eto_NOUN = False\n",
    "                for all_cases_j in all_cases[j]:\n",
    "                    if all_cases_j.score> 0.05 and all_cases_j.tag.POS == 'NOUN':\n",
    "                        eto_NOUN = True\n",
    "                if eto_NOUN:\n",
    "                    odnorod = False\n",
    "                    NOUN_est_ADJF = False\n",
    "                    for ii in range(j+1,len(pos)):\n",
    "                        if pos[ii] =='NOUN':\n",
    "                            for all_cases_j in all_cases[j]:\n",
    "                                for all_cases_z in all_cases[ii]:\n",
    "                                    if all_cases_z.tag.POS == 'ADJF' or all_cases_j.tag.POS == 'ADJF':\n",
    "                                        NOUN_est_ADJF = True\n",
    "                                    #if all_cases_j.score> 0.24 and all_cases_z.score> 0.24 and all_cases_j.tag.case == all_cases_z.tag.case  and all_cases_j.tag.number == all_cases_z.tag.number:\n",
    "                                    if (all_cases_j.tag.case == all_cases_z.tag.case) and (choice_list[j] != 'свет' or choice_list[ii] != 'заря'):\n",
    "                                        odnorod = True\n",
    "                            if odnorod:\n",
    "                                if not NOUN_est_ADJF:\n",
    "                                    #print('Сущ',choice_list[j],choice_list[ii])\n",
    "                                    choice_list[j] = choice_list[j]+ ' [MASK]'\n",
    "                                break    \n",
    "                        \n",
    "                        \n",
    "                        if pos[ii] !='NOUN' and pos[ii] !='ADJF' and pos[ii] !='PREP' and pos[ii] !='PRCL':\n",
    "                            break            \n",
    "                \n",
    "                if  (p == 'CONJ'or choice_list[j] =='да' or choice_list[j] =='ни')  and j>0 and pos[j-1] != 'CONJ':\n",
    "                    if choice_list[j] =='то' and choice_list[j-1] =='не':\n",
    "                            #print('Союз',choice_list[j-1],choice_list[j])\n",
    "                            choice_list[j-1] = '[MASK] '+choice_list[j-1]  \n",
    "                          \n",
    "                    elif choice_list[j] !='ни' or (choice_list[j] =='ни' and (j==0 or choice_list[j-1] !='свет')and (j==len(pos) or choice_list[j+1] !='свет')):\n",
    "                        #print('Союз',choice_list[j],choice_list[j-1],choice_list[j+1])\n",
    "                        for pb in par_b:\n",
    "                            if (j!=0 and choice_list[j-1] ==pb[0]) and (j!=len(pos) and choice_list[j+1] ==pb[1]):\n",
    "                                bad_par = True\n",
    "                        if j==1 and choice_list[j] == 'и':\n",
    "                            bad_par = True\n",
    "                        if choice_list[j] == 'ни' and (j!=len(pos) or choice_list[j+1] =='то'):\n",
    "                            bad_par = True                       \n",
    "                        if not bad_par:  \n",
    "                            choice_list[j] = '[MASK] '+choice_list[j]\n",
    "                       \n",
    "            words = ' '.join(choice_list).replace(' ,',',').replace(' .','.').replace(' !','!').replace(' ?','?').replace(' :',':').replace(' ;',';').replace(' »','»').replace('« ','«')\n",
    "            words = words.replace('[MASK] [MASK]','[MASK]').replace('[MASK] [MASK]','[MASK]')\n",
    "            #print(words)\n",
    "            if words.startswith('[MASK] '):\n",
    "                words = words.replace('[MASK] ','',1)\n",
    "            \n",
    "            result = self.what_mask(words)\n",
    "            #print(result)\n",
    "            if result:\n",
    "                for i in range(1, max(result)+1):\n",
    "                    if i in result:\n",
    "                        words = words.replace(' [MASK]', ',', 1)\n",
    "                    else:\n",
    "                        words = words.replace(' [MASK]', '', 1)\n",
    "            words = words.replace(' [MASK]', '')\n",
    "            #print(words)\n",
    "            sens.append(words)\n",
    "        return sens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c615e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_punctuation = Bert_punctuation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "225c0a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['я, наверное пойду', 'хотя может, и останусь']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_punctuation.predict([\"Я наверное пойду\", \"Хотя может и останусь\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b198da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
